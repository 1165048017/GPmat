function g = mlpKernGradient(kern, x, varargin)

% MLPKERNGRADIENT Gradient of multi-layer perceptron kernel's parameters.

% KERN

if nargin < 4
  [k, innerProd, arg, denom, numer] = mlpKernCompute(kern, x);
else
  [k, innerProd, arg, denom, numer] = mlpKernCompute(kern, x, varargin{1});
end
denom3 = denom.*denom.*denom;
base = kern.variance./sqrt(1-arg.*arg);
baseCovGrad = base.*varargin{end};

if nargin < 4
  vec = diag(innerProd);
  g(1) = sum(sum((innerProd./denom ...
                  -.5*numer./denom3...
                  .*((kern.weightVariance.*vec+kern.biasVariance+1)*vec' ...
                     + vec*(kern.weightVariance.*vec+kern.biasVariance+1)')).*baseCovGrad));
  g(2) = sum(sum((1./denom ...
                  -.5*numer./denom3 ...
                  .*(repmat(vec, 1, size(vec, 1))*kern.weightVariance...
                     + 2*kern.biasVariance + 2 ...
                     +repmat(vec', size(vec, 1), 1)* ...
                     kern.weightVariance)).*baseCovGrad));
else
  vec1 = sum(x.*x, 2);
  vec2 = sum(varargin{1}.*varargin{1}, 2);
  g(1) = sum(sum((innerProd./denom ...
                  -.5*numer./denom3...
                  .*((kern.weightVariance.*vec1+kern.biasVariance+1)*vec2' ...
                     + vec1*(kern.weightVariance.*vec2+kern.biasVariance+1)')).*baseCovGrad));
  g(2) = sum(sum((1./denom ...
                  -.5*numer./denom3 ...
                  .*(repmat(vec1, 1, size(vec2, 1))*kern.weightVariance...
                     + 2*kern.biasVariance + 2 ...
                     +repmat(vec2', size(vec1, 1), 1)* ...
                     kern.weightVariance)).*baseCovGrad));
end
g(3) = sum(sum(k/kern.variance.*varargin{end}));

%/~
if any(isnan(g))
  warning('g is NaN')
end
%~/
